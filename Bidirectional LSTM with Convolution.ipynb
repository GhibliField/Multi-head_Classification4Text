{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nfrom keras.layers import Dense,Input,LSTM,Bidirectional,Activation,Conv1D,GRU\nfrom keras.callbacks import Callback\nfrom keras.layers import Dropout,Embedding,GlobalMaxPooling1D, MaxPooling1D, Add, Flatten\nfrom keras.preprocessing import text, sequence\nfrom keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\nfrom keras import initializers, regularizers, constraints, optimizers, layers, callbacks\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Using TensorFlow backend.\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "['jigsaw-toxic-comment-classification-challenge', 'best-model', 'glove840b300dtxt']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "collapsed": true,
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true
      },
      "cell_type": "code",
      "source": "EMBEDDING_FILE = '../input/glove840b300dtxt/glove.840B.300d.txt'\ntrain = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv')\ntest = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv')",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cf43ac37cbd14d8baa088648c2275123550135d6",
        "collapsed": true,
        "_cell_guid": "e8bd3575-f711-4ca6-a653-8ec1c74c0204",
        "trusted": true
      },
      "cell_type": "code",
      "source": "train[\"comment_text\"].fillna(\"fillna\")\ntest[\"comment_text\"].fillna(\"fillna\")\nX_train = train[\"comment_text\"].str.lower()\ny_train = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values\n\nX_test = test[\"comment_text\"].str.lower()",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "efad6a0ecd758a759f14287a69bfd9cafa8c8fb2",
        "_cell_guid": "da409613-3688-4d2e-a072-f67dee02617b",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "max_features=100000\nmaxlen=150\nembed_size=300",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "70c576f3b0afd3e779df184f788107fb51233424",
        "collapsed": true,
        "_cell_guid": "3b0804b5-d64e-474e-8252-78daa4a4be62",
        "trusted": true
      },
      "cell_type": "code",
      "source": "class RocAucEvaluation(Callback):\n    def __init__(self, validation_data=(), interval=1):\n        super(Callback, self).__init__()\n\n        self.interval = interval\n        self.X_val, self.y_val = validation_data\n\n    def on_epoch_end(self, epoch, logs={}):\n        if epoch % self.interval == 0:\n            y_pred = self.model.predict(self.X_val, verbose=0)\n            score = roc_auc_score(self.y_val, y_pred)\n            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b07e998ccedaf3aaaf4b4e67b207ad5490eb24f7",
        "_cell_guid": "7a665c08-b4a9-4792-b40b-481b3da907e5",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "tok=text.Tokenizer(num_words=max_features,lower=True)\ntok.fit_on_texts(list(X_train)+list(X_test))\nX_train=tok.texts_to_sequences(X_train)\nX_test=tok.texts_to_sequences(X_test)\nx_train=sequence.pad_sequences(X_train,maxlen=maxlen)\nx_test=sequence.pad_sequences(X_test,maxlen=maxlen)",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9488bc9d68dfd1fde1f99d23a9f1ed7b30ceb87f",
        "collapsed": true,
        "_cell_guid": "9e57a7cb-c061-4361-bbe2-05c0486a3f18",
        "trusted": true
      },
      "cell_type": "code",
      "source": "embeddings_index = {}\nwith open(EMBEDDING_FILE,encoding='utf8') as f:\n    for line in f:\n        values = line.rstrip().rsplit(' ')\n        word = values[0]\n        coefs = np.asarray(values[1:], dtype='float32')\n        embeddings_index[word] = coefs\n",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d56ad119931a971b2588355deb726a045764c9ad",
        "collapsed": true,
        "_cell_guid": "e2490100-fc9c-4e46-ae84-7dfa65fcddba",
        "trusted": true
      },
      "cell_type": "code",
      "source": "word_index = tok.word_index\n#prepare embedding matrix\nnum_words = min(max_features, len(word_index) + 1)\nembedding_matrix = np.zeros((num_words, embed_size))\nfor word, i in word_index.items():\n    if i >= max_features:\n        continue\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        # words not found in embedding index will be all-zeros.\n        embedding_matrix[i] = embedding_vector",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "560d3faac051bbb95dae6f1bf7013d52b404533c",
        "_cell_guid": "1a4a1cf3-7faf-4ee4-a72e-a258169778a5",
        "trusted": true
      },
      "cell_type": "code",
      "source": "sequence_input = Input(shape=(maxlen, ))\nx = Embedding(max_features, embed_size, weights=[embedding_matrix],trainable = False)(sequence_input)\nx = SpatialDropout1D(0.2)(x)\nx = Bidirectional(GRU(128, return_sequences=True,dropout=0.1,recurrent_dropout=0.1))(x)\nx = Conv1D(64, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x)\navg_pool = GlobalAveragePooling1D()(x)\nmax_pool = GlobalMaxPooling1D()(x)\nx = concatenate([avg_pool, max_pool]) \n# x = Dense(128, activation='relu')(x)\n# x = Dropout(0.1)(x)\npreds = Dense(6, activation=\"sigmoid\")(x)\nmodel = Model(sequence_input, preds)\nmodel.compile(loss='binary_crossentropy',optimizer=Adam(lr=1e-3),metrics=['accuracy'])",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\nInstructions for updating:\n`NHWC` for data_format is deprecated, use `NWC` instead\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "19975febdf6a0bd3077d8a92da13bb433085ce80",
        "_cell_guid": "46df26aa-adcd-4b2c-8644-76a1e51df2bc",
        "trusted": true
      },
      "cell_type": "code",
      "source": "batch_size = 128\nepochs = 4\nX_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.9, random_state=233)",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n  FutureWarning)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "7956b05d34604689b7a10d56a61640091559eda2",
        "collapsed": true,
        "_cell_guid": "e1962822-5dfb-4249-a714-ce95346150d4",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# filepath=\"../input/best-model/best.hdf5\"\nfilepath=\"weights_base.best.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\nearly = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5)\nra_val = RocAucEvaluation(validation_data=(X_val, y_val), interval = 1)\ncallbacks_list = [ra_val,checkpoint, early]",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f7377e50952ffb6cc14bab3b34442788864eed68",
        "scrolled": false,
        "_cell_guid": "265115a8-296e-4b67-a6fc-02d0a584b501",
        "trusted": true
      },
      "cell_type": "code",
      "source": "model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val),callbacks = callbacks_list,verbose=1)\n#Loading model weights\nmodel.load_weights(filepath)\nprint('Predicting....')\ny_pred = model.predict(x_test,batch_size=1024,verbose=1)",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 143613 samples, validate on 15958 samples\nEpoch 1/4\n143613/143613 [==============================] - 2335s 16ms/step - loss: 0.0561 - acc: 0.9798 - val_loss: 0.0443 - val_acc: 0.9827\n\n ROC-AUC - epoch: 1 - score: 0.986450\n\nEpoch 00001: val_acc improved from -inf to 0.98275, saving model to weights_base.best.hdf5\nEpoch 2/4\n143613/143613 [==============================] - 2359s 16ms/step - loss: 0.0438 - acc: 0.9833 - val_loss: 0.0432 - val_acc: 0.9833\n\n ROC-AUC - epoch: 2 - score: 0.987873\n\nEpoch 00002: val_acc improved from 0.98275 to 0.98329, saving model to weights_base.best.hdf5\nEpoch 3/4\n143613/143613 [==============================] - 2614s 18ms/step - loss: 0.0410 - acc: 0.9841 - val_loss: 0.0428 - val_acc: 0.9837\n\n ROC-AUC - epoch: 3 - score: 0.988525\n\nEpoch 00003: val_acc improved from 0.98329 to 0.98369, saving model to weights_base.best.hdf5\nEpoch 4/4\n143613/143613 [==============================] - 2222s 15ms/step - loss: 0.0388 - acc: 0.9848 - val_loss: 0.0417 - val_acc: 0.9833\n\n ROC-AUC - epoch: 4 - score: 0.989123\n\nEpoch 00004: val_acc did not improve\nPredicting....\n153164/153164 [==============================] - 1096s 7ms/step\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "ddc5afff4b22841fb184e32cc4b19a2225dec451",
        "collapsed": true,
        "_cell_guid": "5c703574-cf76-495f-b800-1fc6c9384ded",
        "trusted": false
      },
      "cell_type": "code",
      "source": "submission = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv')\nsubmission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = y_pred\nsubmission.to_csv('submission.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f28a8748f9726bd1d3ef4dfc63fc97dbf54274d6",
        "collapsed": true,
        "_cell_guid": "bffedb6f-f020-4ff8-b2f5-acd9c5957841",
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}